# ==============================================================================
# Open Agent Builder - Environment Variables
# ==============================================================================
# Copy this file to .env and fill in your actual values
# Never commit .env to version control!
# ==============================================================================

# ------------------------------------------------------------------------------
# DATABASE PROVIDER: Choose Convex (cloud) or PostgreSQL (self-hosted)
# ------------------------------------------------------------------------------
# Set to 'true' to use PostgreSQL, or leave empty/false to use Convex
# Both can be configured - USE_POSTGRES determines which is used
USE_POSTGRES=false

# Option 1: Convex (Cloud) - Easy to get started
# Get this from: https://dashboard.convex.dev
# 1. Create a new project or select existing
# 2. Copy the deployment URL from the dashboard
# Format: https://your-project.convex.cloud
NEXT_PUBLIC_CONVEX_URL=

# Option 2: PostgreSQL (Self-Hosted) - Complete control
# Set USE_POSTGRES=true to use this instead of Convex
# This is configured automatically when using Docker

# ------------------------------------------------------------------------------
# AUTHENTICATION: NextAuth.js (Self-Hosted - NO EXTERNAL SERVICE!)
# ------------------------------------------------------------------------------
# Generate secret with: openssl rand -base64 32
NEXTAUTH_SECRET=
NEXTAUTH_URL=http://localhost:3000

# Database for auth (PostgreSQL in Docker)
DATABASE_URL=postgresql://agent_builder:changeme123@postgres:5432/agent_builder
DB_USER=agent_builder
DB_PASSWORD=changeme123
DB_NAME=agent_builder

# LEGACY: Clerk (if you want to keep using Clerk temporarily)
# NEXT_PUBLIC_CLERK_PUBLISHABLE_KEY=
# CLERK_SECRET_KEY=
# CLERK_JWT_ISSUER_DOMAIN=

# ------------------------------------------------------------------------------
# WEB SCRAPING: Self-Hosted (NO API KEY NEEDED!)
# ------------------------------------------------------------------------------
# Uses Jina.ai (free API) + Browserless (local container)
# No Firecrawl subscription required!

# Jina.ai Reader - Free markdown conversion (no key needed)
JINA_READER_URL=https://r.jina.ai

# Browserless - Local browser automation (included in Docker)
BROWSERLESS_URL=http://browserless:3000

# OPTIONAL: Keep Firecrawl as fallback (if you have existing subscription)
# FIRECRAWL_API_KEY=

# ------------------------------------------------------------------------------
# LOCAL LLM: Ollama (Included in Docker setup - NO API KEY NEEDED!)
# ------------------------------------------------------------------------------
# Ollama runs locally in Docker and provides free, local LLM inference
# No API keys or cloud accounts required!
# Default models automatically pulled: llama3.2:3b, qwen2.5-coder:7b
# Access Ollama directly at: http://localhost:11434
OLLAMA_BASE_URL=http://ollama:11434

# ------------------------------------------------------------------------------
# OPTIONAL: Cloud LLM Providers (if you prefer cloud-based models)
# ------------------------------------------------------------------------------
# Users can also add their own keys via Settings â†’ API Keys in the UI
# Adding keys here provides default fallback for all users
# Note: With Ollama running locally, these are completely optional

# Anthropic Claude (RECOMMENDED for MCP tool support)
# Get from: https://console.anthropic.com
# Supports: Claude Haiku 4.5, Claude Sonnet 4.5
# Native MCP protocol support for tool calling
ANTHROPIC_API_KEY=

# OpenAI GPT
# Get from: https://platform.openai.com/api-keys
# Supports: gpt-5, gpt-4, gpt-3.5-turbo
# Note: MCP support coming soon
OPENAI_API_KEY=

# Groq (Fast inference for open models)
# Get from: https://console.groq.com
# Supports: Llama, Mixtral, and other open models
# Note: MCP support coming soon
GROQ_API_KEY=

# ------------------------------------------------------------------------------
# OPTIONAL: E2B Code Interpreter
# ------------------------------------------------------------------------------
# Get from: https://e2b.dev
# Enables sandboxed code execution in Transform nodes
# Provides secure Python code execution environment
E2B_API_KEY=

# ------------------------------------------------------------------------------
# Docker/Application Settings
# ------------------------------------------------------------------------------
# Environment mode (development, production)
NODE_ENV=development

# Application port (default: 3000)
PORT=3000

# Disable Next.js telemetry (optional)
NEXT_TELEMETRY_DISABLED=1

# ------------------------------------------------------------------------------
# Setup Checklist
# ------------------------------------------------------------------------------
# [ ] Created Convex project and copied NEXT_PUBLIC_CONVEX_URL
# [ ] Created Clerk application and copied authentication keys
# [ ] Set up Clerk JWT template for Convex integration
# [ ] Obtained Firecrawl API key
# [ ] (Optional) Added at least one LLM provider API key
# [ ] (Optional) Added E2B API key for code execution
# [ ] Updated convex/auth.config.ts with your Clerk domain
# [ ] Ran: docker-compose up
# ------------------------------------------------------------------------------

